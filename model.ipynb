{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table and CSV Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_result_table(method_name, gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best):\n",
    "    # Create a dictionary with column names as keys and corresponding values\n",
    "    data = {\n",
    "        f'{method_name}': 'f1_score',\n",
    "        'GaussianNB': [gauss_best],\n",
    "        'KNN': [knn_best],\n",
    "        'XGBoost': [xgb_best],\n",
    "        'Random Forest': [rf_best],\n",
    "        'SVM': [svm_best],\n",
    "        'Logistic Regression': [log_best]\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame from the dictionary and transpose it\n",
    "    result_table = pd.DataFrame(data).transpose()\n",
    "    \n",
    "    # Set column names from the first row of the transposed DataFrame\n",
    "    result_table.columns = result_table.iloc[0]\n",
    "    \n",
    "    # Remove the first row from the DataFrame\n",
    "    result_table = result_table.iloc[1:]\n",
    "    \n",
    "    # Return the resulting DataFrame\n",
    "    return result_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_creator(method_name):\n",
    "    # Declare global variables for method_name, and the best scores for each method\n",
    "    global gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best\n",
    "    \n",
    "    # Define the variable names and corresponding values to be written to the CSV file\n",
    "    variables = ['Method', 'gauss_best', 'knn_best', 'xgb_best', 'rf_best', 'svm_best', 'log_best']\n",
    "    values = [method_name, f'{gauss_best:.3f}', f'{knn_best:.3f}', f'{xgb_best:.3f}', f'{rf_best:.3f}', f'{svm_best:.3f}', f'{log_best:.3f}']\n",
    "\n",
    "    # Specify the CSV file path based on the method_name\n",
    "    csv_filename = f'model_data/{method_name}/{method_name}_values.csv'\n",
    "    \n",
    "    # Open the CSV file in write mode, and create a CSV writer\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write the header (variable names) to the CSV file\n",
    "        csv_writer.writerow(variables)\n",
    "        \n",
    "        # Write the values to the CSV file\n",
    "        csv_writer.writerow(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Practitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import rmtree\n",
    "from joblib import dump\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def save_data(X_train, X_test, y_train, y_test, f1_value, folder_path):\n",
    "    # Convert dataset to a DataFrame and save it as a CSV file in the specified folder\n",
    "    pd.DataFrame(X_train).to_csv(f'{folder_path}/{f1_value:.3f}_X_train.csv', index=False)\n",
    "    pd.DataFrame(X_test).to_csv(f'{folder_path}/{f1_value:.3f}_X_test.csv', index=False)\n",
    "    pd.DataFrame(y_train).to_csv(f'{folder_path}/{f1_value:.3f}_y_train.csv', index=False)\n",
    "    pd.DataFrame(y_test).to_csv(f'{folder_path}/{f1_value:.3f}_y_test.csv', index=False)\n",
    "\n",
    "def train_and_save_model(model, method_name, X_train, X_test, y_train, y_test, model_name, model_best):\n",
    "    model_instance = model.fit(X_train, y_train) # Train the model on the training data\n",
    "    \n",
    "    y_test_pred = model_instance.predict(X_test) # Make predictions on the test set\n",
    "    \n",
    "    f1_value = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1 score for the model's predictions\n",
    "    \n",
    "    # Check if the current model has a better F1 score than the previous best\n",
    "    if f1_value > model_best:\n",
    "        folder_path = f'model_data/{method_name}/{model_name.lower()}' # Define the folder path for saving model-related data\n",
    "        \n",
    "        # Check if the folder already exists; if yes, remove it\n",
    "        if os.path.exists(folder_path):\n",
    "            rmtree(folder_path)\n",
    "        \n",
    "        os.makedirs(folder_path) # Create a new folder for the model data\n",
    "        \n",
    "        # Save the training and testing data, and the model itself\n",
    "        save_data(X_train, X_test, y_train, y_test, f1_value, folder_path)\n",
    "        dump(model_instance, f'{folder_path}/{model_name.lower()}-{f1_value:.3f}.joblib')\n",
    "        \n",
    "        # Update the model_best variable with the new best F1 value\n",
    "        model_best = f1_value\n",
    "    \n",
    "    # Return the model_best value\n",
    "    return model_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logistic_regression(method_name, X_train, X_test, y_train, y_test):\n",
    "    global log_best # Declare the log_best variable as a global variable\n",
    "    \n",
    "    logreg = LogisticRegression() # Create a Logistic Regression model instance\n",
    "    \n",
    "    # Train the model and save its performance metrics\n",
    "    log_best = train_and_save_model(logreg, method_name, X_train, X_test, y_train.ravel(), y_test, 'Logistic Regression', log_best)\n",
    "\n",
    "def logistic_regression_tuned(method_name, X_train, X_test, y_train, y_test):\n",
    "    global log_best\n",
    "    \n",
    "    # Create a Logistic Regression model instance with specific hyperparameters\n",
    "    logreg = LogisticRegression(penalty='l2', C=1.0)\n",
    "    \n",
    "    log_best = train_and_save_model(logreg, method_name, X_train, X_test, y_train.ravel(), y_test, 'Logistic Regression', log_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def xgb_classifier(method_name, X_train, X_test, y_train, y_test):\n",
    "    global xgb_best # Declare the xgb_best variable as a global variable\n",
    "\n",
    "    xgb = XGBClassifier() # Create an XGBoost model instance\n",
    "\n",
    "    # Train the model and save its performance metrics\n",
    "    xgb_best = train_and_save_model(xgb, method_name, X_train, X_test, y_train, y_test, 'XGB Classifier', xgb_best)\n",
    "\n",
    "def xgb_classifier_tuned(method_name, X_train, X_test, y_train, y_test):\n",
    "    global xgb_best\n",
    "\n",
    "    # Create an XGBoost model instance with specific hyperparameters\n",
    "    xgb = XGBClassifier(n_estimators = 50, learning_rate = 0.01, max_depth = 3, subsample = 0.8, colsample_bytree = 1.0)\n",
    "    \n",
    "    xgb_best = train_and_save_model(xgb, method_name, X_train, X_test, y_train, y_test, 'XGB Classifier', xgb_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest_classifier(method_name, X_train, X_test, y_train, y_test):\n",
    "    global rf_best # Declare the rf_best variable as a global variable\n",
    "\n",
    "    rf = RandomForestClassifier() # Create a Random Forest model instance\n",
    "\n",
    "    # Train the model and save its performance metrics\n",
    "    rf_best = train_and_save_model(rf, method_name, X_train, X_test, y_train.ravel(), y_test, 'Random Forest Classifier', rf_best)\n",
    "\n",
    "def random_forest_classifier_tuned(method_name, X_train, X_test, y_train, y_test):\n",
    "    global rf_best\n",
    "\n",
    "    # Create a Random Forest model instance with specific hyperparameters\n",
    "    rf = RandomForestClassifier(min_samples_split=5, n_estimators=50)\n",
    "\n",
    "    rf_best = train_and_save_model(rf, method_name, X_train, X_test, y_train.ravel(), y_test, 'Random Forest Classifier', rf_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm(method_name, X_train, X_test, y_train, y_test):\n",
    "    global svm_best # Declare the svm_best variable as a global variable\n",
    "\n",
    "    svm = SVC() # Create an SVM model instance\n",
    "    \n",
    "    # Train the model and save its performance metrics\n",
    "    svm_best = train_and_save_model(svm, method_name, X_train, X_test, y_train.ravel(), y_test, 'SVM', svm_best)\n",
    "\n",
    "def svm_tuned(method_name, X_train, X_test, y_train, y_test):\n",
    "    global svm_best\n",
    "\n",
    "    # Create an SVM model instance with specific hyperparameters\n",
    "    svm = SVC(C=1, kernel='linear')\n",
    "\n",
    "    svm_best = train_and_save_model(svm, method_name, X_train, X_test, y_train.ravel(), y_test, 'SVM', svm_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def gaussian_nb(method_name, X_train, X_test, y_train, y_test):\n",
    "    global gauss_best # Declare the gauss_best variable as a global variable\n",
    "\n",
    "    gauss = GaussianNB() # Create a Gaussian Naive Bayes model instance\n",
    "\n",
    "    # Train the model and save its performance metrics\n",
    "    gauss_best = train_and_save_model(gauss, method_name, X_train, X_test, y_train.ravel(), y_test, 'GaussianNB', gauss_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def k_neigbors_classifier(method_name, X_train, X_test, y_train, y_test):\n",
    "    global knn_best # Declare the knn_best variable as a global variable\n",
    "\n",
    "    knn = KNeighborsClassifier() # Create a K-Nearest Neighbors model instance\n",
    "\n",
    "    # Train the model and save its performance metrics\n",
    "    knn_best = train_and_save_model(knn, method_name, X_train, X_test, y_train.ravel(), y_test, 'KNeighborsClassifier', knn_best)\n",
    "\n",
    "def k_neigbors_classifier_tuned(method_name, X_train, X_test, y_train, y_test):\n",
    "    global knn_best\n",
    "\n",
    "    # Create a K-Nearest Neighbors model instance with specific hyperparameters\n",
    "    knn = KNeighborsClassifier(leaf_size=10, n_neighbors=3, p=1)\n",
    "\n",
    "    knn_best = train_and_save_model(knn, method_name, X_train, X_test, y_train.ravel(), y_test, 'KNeighborsClassifier', knn_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Best F1 Score For Every Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_f1_score(method_name):\n",
    "    csv_file_path = f\"model_data/{method_name}/{method_name}_values.csv\"\n",
    "\n",
    "    # Check if the directory exists, if not, create it\n",
    "    directory = os.path.dirname(csv_file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Check if CSV file exists\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        # Create the CSV file with headers and default values\n",
    "        data = {\n",
    "            \"Method\": [method_name],\n",
    "            \"gauss_best\": [0],\n",
    "            \"knn_best\": [0],\n",
    "            \"xgb_best\": [0],\n",
    "            \"rf_best\": [0],\n",
    "            \"svm_best\": [0],\n",
    "            \"log_best\": [0]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    # Read the existing CSV file\n",
    "    csv_file = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Select relevant columns\n",
    "    selected_columns = [\"gauss_best\", \"knn_best\", \"xgb_best\", \"rf_best\", \"svm_best\", \"log_best\"]\n",
    "    selected_data = csv_file[selected_columns]\n",
    "\n",
    "    # Extract best values\n",
    "    gauss_best = selected_data[\"gauss_best\"].iloc[0]\n",
    "    knn_best = selected_data[\"knn_best\"].iloc[0]\n",
    "    xgb_best = selected_data[\"xgb_best\"].iloc[0]\n",
    "    rf_best = selected_data[\"rf_best\"].iloc[0]\n",
    "    svm_best = selected_data[\"svm_best\"].iloc[0]\n",
    "    log_best = selected_data[\"log_best\"].iloc[0]\n",
    "\n",
    "    return gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    for row in df.columns:\n",
    "        # Calculate the distribution and percent distribution of values ​​in the current column\n",
    "        data_distribution = df[row].value_counts() \n",
    "        distribution_percentage = data_distribution / data_distribution.sum() * 100\n",
    "        \n",
    "        # Check if the maximum percentage is greater than 80% and delete the column if greater\n",
    "        if distribution_percentage.max() > 80 and row != \"Number of Bugs\":\n",
    "            df.drop(columns=[row], inplace=True)\n",
    "            \n",
    "    # Drop specified columns 'Hash' and 'LongName'\n",
    "    df.drop(columns=['Hash'], inplace=True)\n",
    "    df.drop(columns=['LongName'], inplace=True)\n",
    "\n",
    "    # Transform 'Number of Bugs' column values to 1 if greater than 1, else keep the same value\n",
    "    df[\"Number of Bugs\"] = df[\"Number of Bugs\"].apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "    # Calculate the correlation of each feature with the last column and drop columns with low correlation\n",
    "    correlation_with_last_column = df.corr().iloc[:-1, -1].abs()\n",
    "    df = df.drop(columns=correlation_with_last_column[correlation_with_last_column < 0.01].index)\n",
    "\n",
    "    # Shuffle the DataFrame and reset the index\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Keep the 3000 rows if the DataFrame has more than 3000 rows\n",
    "    df = df.head(3000) if len(df) > 3000 else df\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def main(df, method_name):\n",
    "    # Separate features (X) and target variable (y)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1].values.reshape(-1, 1)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=144, shuffle=True)\n",
    "    \n",
    "    # Apply Min-Max scaling to the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "    # Perform original and tuned models\n",
    "    logistic_regression(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    logistic_regression_tuned(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    xgb_classifier(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    xgb_classifier_tuned(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    random_forest_classifier(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    random_forest_classifier_tuned(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    svm(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    svm_tuned(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    gaussian_nb(method_name, X_train, X_test, y_train, y_test)\n",
    "    k_neigbors_classifier(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    k_neigbors_classifier_tuned(method_name, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "    # Create and save CSV files with the results\n",
    "    csv_creator(method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Android Universal Image Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/Android-Universal-Image-Loader/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"auil\")\n",
    "\n",
    "# Training and evaluation process to process a minimum of 50 times or a total of 150000 rows of data\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"auil\")\n",
    "\n",
    "create_result_table(\"auil\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antlr v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/antlr4/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"antlr4\")\n",
    "\n",
    "# Training and evaluation process to process a minimum of 50 times or a total of 150000 rows of data\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"antlr4\")\n",
    "\n",
    "create_result_table(\"antlr4\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadleaf Commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/BroadleafCommerce/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"BroadleafCommerce\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"BroadleafCommerce\")\n",
    "\n",
    "create_result_table(\"BroadleafCommerce\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ceylon IDE Eclipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ceylon-ide-eclipse/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"ceylon-ide-eclipse\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"ceylon-ide-eclipse\")\n",
    "\n",
    "create_result_table(\"ceylon-ide-eclipse\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/elasticsearch/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"elastic-search\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"elastic-search\")\n",
    "\n",
    "create_result_table(\"elastic-search\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hazelcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hazelcast/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"hazelcast\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"hazelcast\")\n",
    "\n",
    "create_result_table(\"hazelcast\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/junit/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"jUnit\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"jUnit\")\n",
    "\n",
    "create_result_table(\"jUnit\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/MapDB/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"MapDB\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"MapDB\")\n",
    "\n",
    "create_result_table(\"MapDB\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mcMMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mcMMO/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"mcMMO\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"mcMMO\")\n",
    "\n",
    "create_result_table(\"mcMMO\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mct/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"MCT\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"MCT\")\n",
    "\n",
    "create_result_table(\"MCT\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neo4J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/neo4j/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"neo4J\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"neo4J\")\n",
    "\n",
    "create_result_table(\"neo4J\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/netty/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"Netty\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"Netty\")\n",
    "\n",
    "create_result_table(\"Netty\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## orientDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/orientdb/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"orientDB\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"orientDB\")\n",
    "\n",
    "create_result_table(\"orientDB\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oryx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/oryx/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"Oryx\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"Oryx\")\n",
    "\n",
    "create_result_table(\"Oryx\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titan/class.csv')\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best = get_best_f1_score(\"Titan\")\n",
    "\n",
    "# Repeat the training and evaluation process a maximum of 50 times or until a certain dataset size is reached\n",
    "for _ in range(max(50,150000 // len(df))):\n",
    "    main(df, \"Titan\")\n",
    "\n",
    "create_result_table(\"Titan\", gauss_best, knn_best, xgb_best, rf_best, svm_best, log_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
